#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸“ä¸šé‡‘èæ•°æ®é‡‡é›†å™¨
æ”¯æŒå¤šæ•°æ®æºï¼Œè®°å½•è·å–æ—¶é—´å’Œæ¥æº
"""

import requests
import json
import logging
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional, Tuple
import sqlite3
import time
import random
from dataclasses import dataclass

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class DataSource:
    """æ•°æ®æºé…ç½®ç±»"""
    name: str
    base_url: str
    api_endpoint: str
    api_key: Optional[str] = None
    headers: Optional[Dict] = None
    rate_limit: int = 60  # æ¯åˆ†é’Ÿè¯·æ±‚æ¬¡æ•°é™åˆ¶
    auth_required: bool = False
    data_format: str = 'json'

class ProfessionalDataCollector:
    """ä¸“ä¸šé‡‘èæ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, db_path: str = 'family_wealth_professional.db'):
        self.db_path = db_path
        self.connection = sqlite3.connect(db_path)
        self.connection.row_factory = sqlite3.Row
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # é…ç½®æ•°æ®æº
        self.data_sources = self._setup_data_sources()
        logger.info("âœ… æ•°æ®é‡‡é›†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_data_sources(self) -> Dict[str, DataSource]:
        """é…ç½®æ•°æ®æº"""
        return {
            'fred': DataSource(
                name='Federal Reserve Economic Data',
                base_url='https://api.stlouisfed.org',
                api_endpoint='/fred/series/observations',
                api_key='YOUR_FRED_API_KEY',  # éœ€è¦ç”³è¯·APIå¯†é’¥
                rate_limit=120
            ),
            'yahoo_finance': DataSource(
                name='Yahoo Finance',
                base_url='https://query1.finance.yahoo.com',
                api_endpoint='/v8/finance/chart',
                rate_limit=2000
            ),
            'worldbank': DataSource(
                name='World Bank Open Data',
                base_url='http://api.worldbank.org',
                api_endpoint='/v2/country/all/indicator',
                data_format='xml',
                rate_limit=150
            ),
            'sec_edgar': DataSource(
                name='SEC EDGAR Database',
                base_url='https://data.sec.gov',
                api_endpoint='/api/xbrl/companyfacts',
                rate_limit=10
            )
        }
    
    def collect_market_data(self, symbols: List[str], period: str = '1y') -> int:
        """æ”¶é›†è‚¡ç¥¨å¸‚åœºæ•°æ®"""
        logger.info(f"ğŸ“Š å¼€å§‹æ”¶é›† {len(symbols)} ä¸ªæ ‡çš„çš„å¸‚åœºæ•°æ®...")
        collected_count = 0
        
        for symbol in symbols:
            try:
                data = self._fetch_yahoo_finance_data(symbol, period)
                if data:
                    self._store_market_data(data, 'Yahoo Finance')
                    collected_count += 1
                    logger.info(f"âœ… æˆåŠŸæ”¶é›† {symbol} æ•°æ® ({len(data)} æ¡è®°å½•)")
                
                # éµå®ˆé€Ÿç‡é™åˆ¶
                time.sleep(60 / self.data_sources['yahoo_finance'].rate_limit)
                
            except Exception as e:
                logger.error(f"âŒ æ”¶é›† {symbol} æ•°æ®å¤±è´¥: {e}")
                continue
        
        logger.info(f"ğŸ‰ å¸‚åœºæ•°æ®æ”¶é›†å®Œæˆï¼Œå…±æ”¶é›† {collected_count} ä¸ªæ ‡çš„")
        return collected_count
    
    def _fetch_yahoo_finance_data(self, symbol: str, period: str) -> Optional[List[Dict]]:
        """ä»Yahoo Financeè·å–æ•°æ®"""
        try:
            url = f"{self.data_sources['yahoo_finance'].base_url}{self.data_sources['yahoo_finance'].api_endpoint}/{symbol}"
            params = {
                'range': period,
                'interval': '1d',
                'indicators': 'quote'
            }
            
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            
            data = response.json()
            
            if 'chart' not in data or 'result' not in data['chart']:
                logger.warning(f"Yahoo Financeè¿”å›æ— æ•ˆæ•°æ®æ ¼å¼: {symbol}")
                return None
            
            result = data['chart']['result'][0]
            if 'timestamp' not in result or 'indicators' not in result:
                return None
            
            quotes = result['indicators']['quote'][0]
            timestamps = result['timestamp']
            
            market_data = []
            for i, timestamp in enumerate(timestamps):
                try:
                    market_data.append({
                        'symbol': symbol,
                        'date': datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d'),
                        'open': float(quotes['open'][i]) if quotes['open'][i] is not None else None,
                        'high': float(quotes['high'][i]) if quotes['high'][i] is not None else None,
                        'low': float(quotes['low'][i]) if quotes['low'][i] is not None else None,
                        'close': float(quotes['close'][i]) if quotes['close'][i] is not None else None,
                        'volume': int(quotes['volume'][i]) if quotes['volume'][i] is not None else None,
                        'adjusted_close': float(quotes['close'][i]) if quotes['close'][i] is not None else None
                    })
                except (TypeError, ValueError, IndexError):
                    continue  # è·³è¿‡æ— æ•ˆæ•°æ®ç‚¹
            
            return market_data
            
        except Exception as e:
            logger.error(f"Yahoo Financeæ•°æ®è·å–å¤±è´¥ {symbol}: {e}")
            return None
    
    def collect_economic_indicators(self, indicators: List[str], 
                                  start_date: str = '2020-01-01') -> int:
        """æ”¶é›†å®è§‚ç»æµæŒ‡æ ‡"""
        logger.info(f"ğŸ“ˆ å¼€å§‹æ”¶é›† {len(indicators)} ä¸ªç»æµæŒ‡æ ‡...")
        collected_count = 0
        
        # FREDæŒ‡æ ‡æ˜ å°„
        fred_indicators = {
            'GDP': 'Gross Domestic Product',
            'UNRATE': 'Unemployment Rate',
            'CPIAUCSL': 'Consumer Price Index',
            'FEDFUNDS': 'Federal Funds Rate',
            'GS10': '10-Year Treasury Constant Maturity Rate'
        }
        
        for indicator in indicators:
            if indicator in fred_indicators:
                try:
                    data = self._fetch_fred_data(indicator, start_date)
                    if data:
                        self._store_economic_data(data, indicator, 'FRED')
                        collected_count += 1
                        logger.info(f"âœ… æˆåŠŸæ”¶é›† {indicator} æ•°æ® ({len(data)} æ¡è®°å½•)")
                    
                    time.sleep(60 / self.data_sources['fred'].rate_limit)
                    
                except Exception as e:
                    logger.error(f"âŒ æ”¶é›† {indicator} æ•°æ®å¤±è´¥: {e}")
                    continue
        
        logger.info(f"ğŸ‰ ç»æµæŒ‡æ ‡æ”¶é›†å®Œæˆï¼Œå…±æ”¶é›† {collected_count} ä¸ªæŒ‡æ ‡")
        return collected_count
    
    def _fetch_fred_data(self, series_id: str, start_date: str) -> Optional[List[Dict]]:
        """ä»FREDè·å–ç»æµæ•°æ®"""
        try:
            # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦çœŸå®çš„FRED APIå¯†é’¥
            # æš‚æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®ç”¨äºæ¼”ç¤º
            logger.warning(f"FRED APIéœ€è¦æ³¨å†Œå¯†é’¥ï¼Œè¿”å›æ¨¡æ‹Ÿæ•°æ®: {series_id}")
            return self._generate_mock_economic_data(series_id, start_date)
            
        except Exception as e:
            logger.error(f"FREDæ•°æ®è·å–å¤±è´¥ {series_id}: {e}")
            return None
    
    def _generate_mock_economic_data(self, indicator: str, start_date: str) -> List[Dict]:
        """ç”Ÿæˆæ¨¡æ‹Ÿç»æµæ•°æ®"""
        start = datetime.strptime(start_date, '%Y-%m-%d')
        end = datetime.now()
        days_diff = (end - start).days
        
        data = []
        base_values = {
            'GDP': 21000,  # å•ä½ï¼šåäº¿ç¾å…ƒ
            'UNRATE': 3.5,  # å•ä½ï¼šç™¾åˆ†æ¯”
            'CPIAUCSL': 290,  # CPIæŒ‡æ•°
            'FEDFUNDS': 2.5,  # è”é‚¦åŸºé‡‘åˆ©ç‡
            'GS10': 3.2  # 10å¹´æœŸå›½å€ºæ”¶ç›Šç‡
        }
        
        base_value = base_values.get(indicator, 100)
        trend_direction = random.choice([-1, 1])  # éšæœºè¶‹åŠ¿æ–¹å‘
        
        for i in range(0, days_diff, 30):  # æ¯æœˆä¸€æ¡æ•°æ®
            current_date = start + timedelta(days=i)
            if current_date > end:
                break
                
            # æ·»åŠ è¶‹åŠ¿å’Œéšæœºæ³¢åŠ¨
            trend = trend_direction * (i / 365) * 2  # å¹´åŒ–2%çš„è¶‹åŠ¿
            noise = random.normalvariate(0, base_value * 0.02)  # 2%çš„æ ‡å‡†å·®
            
            value = base_value * (1 + trend/100) + noise
            
            # ç¡®ä¿åˆç†èŒƒå›´
            if indicator == 'UNRATE':
                value = max(2.0, min(15.0, value))
            elif indicator == 'FEDFUNDS' or indicator == 'GS10':
                value = max(0.0, min(20.0, value))
            
            data.append({
                'indicator_name': indicator,
                'country_code': 'US',
                'date': current_date.strftime('%Y-%m-%d'),
                'value': round(value, 2),
                'unit': self._get_indicator_unit(indicator),
                'frequency': 'monthly'
            })
        
        return data
    
    def _get_indicator_unit(self, indicator: str) -> str:
        """è·å–æŒ‡æ ‡å•ä½"""
        units = {
            'GDP': 'Billions USD',
            'UNRATE': 'Percent',
            'CPIAUCSL': 'Index',
            'FEDFUNDS': 'Percent',
            'GS10': 'Percent'
        }
        return units.get(indicator, '')
    
    def _store_market_data(self, data: List[Dict], source: str):
        """å­˜å‚¨å¸‚åœºæ•°æ®åˆ°æ•°æ®åº“"""
        cursor = self.connection.cursor()
        
        for record in data:
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO market_data 
                    (symbol, date, open_price, high_price, low_price, close_price, 
                     volume, adjusted_close, source, fetched_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    record['symbol'],
                    record['date'],
                    record['open'],
                    record['high'],
                    record['low'],
                    record['close'],
                    record['volume'],
                    record['adjusted_close'],
                    source,
                    datetime.now().isoformat()
                ))
            except Exception as e:
                logger.error(f"å­˜å‚¨å¸‚åœºæ•°æ®å¤±è´¥: {e}")
                continue
        
        self.connection.commit()
    
    def _store_economic_data(self, data: List[Dict], indicator_name: str, source: str):
        """å­˜å‚¨ç»æµæ•°æ®åˆ°æ•°æ®åº“"""
        cursor = self.connection.cursor()
        
        for record in data:
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO economic_indicators 
                    (indicator_name, country_code, date, value, unit, frequency, source, fetched_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    indicator_name,
                    record['country_code'],
                    record['date'],
                    record['value'],
                    record['unit'],
                    record['frequency'],
                    source,
                    datetime.now().isoformat()
                ))
            except Exception as e:
                logger.error(f"å­˜å‚¨ç»æµæ•°æ®å¤±è´¥: {e}")
                continue
        
        self.connection.commit()
    
    def collect_tax_policy_data(self) -> int:
        """æ”¶é›†ç¨æ”¶æ”¿ç­–æ•°æ®"""
        logger.info("âš–ï¸ å¼€å§‹æ”¶é›†ç¨æ”¶æ”¿ç­–æ•°æ®...")
        
        # é¢„å®šä¹‰çš„ç¨æ”¶æ”¿ç­–æ•°æ®
        tax_policies = [
            {
                'policy_type': 'Corporate Tax Rate',
                'jurisdiction': 'United States',
                'effective_date': '2018-01-01',
                'expiration_date': None,
                'rate_percentage': 21.0,
                'rate_type': 'flat',
                'exemption_amount': None,
                'deduction_limit': None,
                'policy_description': 'Tax Cuts and Jobs Act - ä¼ä¸šç¨ç‡ä»35%é™è‡³21%',
                'source_document': 'Tax Cuts and Jobs Act of 2017',
                'verified': True
            },
            {
                'policy_type': 'Capital Gains Tax',
                'jurisdiction': 'United States',
                'effective_date': '2003-01-01',
                'expiration_date': None,
                'rate_percentage': 15.0,
                'rate_type': 'flat',
                'exemption_amount': None,
                'deduction_limit': None,
                'policy_description': 'Jobs and Growth Tax Relief Reconciliation Act - èµ„æœ¬åˆ©å¾—ç¨ç‡é™è‡³15%',
                'source_document': 'JGTRRA 2003',
                'verified': True
            }
        ]
        
        cursor = self.connection.cursor()
        stored_count = 0
        
        for policy in tax_policies:
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO tax_policy_history 
                    (policy_type, jurisdiction, effective_date, expiration_date, rate_percentage,
                     rate_type, exemption_amount, deduction_limit, policy_description, 
                     source_document, verified, updated_at)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    policy['policy_type'],
                    policy['jurisdiction'],
                    policy['effective_date'],
                    policy['expiration_date'],
                    policy['rate_percentage'],
                    policy['rate_type'],
                    policy['exemption_amount'],
                    policy['deduction_limit'],
                    policy['policy_description'],
                    policy['source_document'],
                    policy['verified'],
                    datetime.now().isoformat()
                ))
                stored_count += 1
            except Exception as e:
                logger.error(f"å­˜å‚¨ç¨æ”¶æ”¿ç­–æ•°æ®å¤±è´¥: {e}")
                continue
        
        self.connection.commit()
        logger.info(f"âœ… ç¨æ”¶æ”¿ç­–æ•°æ®æ”¶é›†å®Œæˆï¼Œå…±å­˜å‚¨ {stored_count} æ¡è®°å½•")
        return stored_count
    
    def get_collection_statistics(self) -> Dict:
        """è·å–æ•°æ®æ”¶é›†ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        cursor = self.connection.cursor()
        
        # å¸‚åœºæ•°æ®ç»Ÿè®¡
        cursor.execute("SELECT COUNT(DISTINCT symbol) as symbols, COUNT(*) as total_records FROM market_data")
        market_stats = cursor.fetchone()
        stats['market_data'] = {
            'unique_symbols': market_stats['symbols'],
            'total_records': market_stats['total_records']
        }
        
        # ç»æµæŒ‡æ ‡ç»Ÿè®¡
        cursor.execute("SELECT COUNT(DISTINCT indicator_name) as indicators, COUNT(*) as total_records FROM economic_indicators")
        econ_stats = cursor.fetchone()
        stats['economic_indicators'] = {
            'unique_indicators': econ_stats['indicators'],
            'total_records': econ_stats['total_records']
        }
        
        # æ•°æ®æºç»Ÿè®¡
        cursor.execute("SELECT source, COUNT(*) as count FROM market_data GROUP BY source")
        source_stats = cursor.fetchall()
        stats['data_sources'] = {row['source']: row['count'] for row in source_stats}
        
        # æœ€æ–°æ•°æ®æ—¶é—´
        cursor.execute("SELECT MAX(date) as latest_date FROM market_data")
        latest_date = cursor.fetchone()['latest_date']
        stats['latest_data_date'] = latest_date
        
        return stats
    
    def close(self):
        """å…³é—­è¿æ¥"""
        self.connection.close()
        self.session.close()
        logger.info("ğŸ”’ æ•°æ®é‡‡é›†å™¨è¿æ¥å·²å…³é—­")

def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºæ•°æ®é‡‡é›†åŠŸèƒ½"""
    try:
        # åˆå§‹åŒ–æ•°æ®é‡‡é›†å™¨
        collector = ProfessionalDataCollector()
        
        # æ”¶é›†å¸‚åœºæ•°æ®
        market_symbols = ['^GSPC', 'AAPL', 'GOOGL', 'MSFT', 'TSLA']
        market_count = collector.collect_market_data(market_symbols, '2y')
        
        # æ”¶é›†ç»æµæŒ‡æ ‡
        indicators = ['GDP', 'UNRATE', 'CPIAUCSL', 'FEDFUNDS', 'GS10']
        econ_count = collector.collect_economic_indicators(indicators, '2020-01-01')
        
        # æ”¶é›†ç¨æ”¶æ”¿ç­–æ•°æ®
        tax_count = collector.collect_tax_policy_data()
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        stats = collector.get_collection_statistics()
        logger.info("ğŸ“Š æ•°æ®æ”¶é›†ç»Ÿè®¡:")
        logger.info(f"  å¸‚åœºæ•°æ®: {stats['market_data']['unique_symbols']} ä¸ªæ ‡çš„, {stats['market_data']['total_records']} æ¡è®°å½•")
        logger.info(f"  ç»æµæŒ‡æ ‡: {stats['economic_indicators']['unique_indicators']} ä¸ªæŒ‡æ ‡, {stats['economic_indicators']['total_records']} æ¡è®°å½•")
        logger.info(f"  ç¨æ”¶æ”¿ç­–: {tax_count} æ¡è®°å½•")
        logger.info(f"  æœ€æ–°æ•°æ®æ—¥æœŸ: {stats['latest_data_date']}")
        logger.info(f"  æ•°æ®æ¥æº: {stats['data_sources']}")
        
        collector.close()
        logger.info("ğŸ‰ æ•°æ®é‡‡é›†æ¼”ç¤ºå®Œæˆ!")
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®é‡‡é›†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        raise

if __name__ == "__main__":
    main()