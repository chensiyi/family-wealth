# ä¿¡æ¯æ”¶é›†å™¨ (Data Collector)

> **æ–‡ä»¶æ‘˜è¦**: æœ¬æ–‡ä»¶è¯¦ç»†å®šä¹‰ä¿¡æ¯æ”¶é›†å™¨çš„æŠ€æœ¯æ¶æ„ã€æ•°æ®é‡‡é›†ç­–ç•¥å’Œè´¨é‡æ§åˆ¶è§„èŒƒã€‚ä½œä¸ºæ²™ç›˜ç³»ç»Ÿçš„æ•°æ®åŸºç¡€ï¼Œæä¾›å¤šæºé‡‘èæ•°æ®çš„é‡‡é›†ã€æ¸…æ´—ã€éªŒè¯å’Œå­˜å‚¨åŠŸèƒ½ã€‚

## ğŸ¯ ç³»ç»Ÿå®šä½ä¸ç›®æ ‡

ä¿¡æ¯æ”¶é›†å™¨æ˜¯å®¶æ—è´¢å¯Œç®¡ç†ç³»ç»Ÿçš„æ•°æ®åŸºç¡€è®¾æ–½å±‚ï¼Œè´Ÿè´£ï¼š
- **æ•°æ®é‡‡é›†**ï¼šä»æƒå¨é‡‘èæ•°æ®æºè·å–é«˜è´¨é‡æ•°æ®
- **è´¨é‡æ§åˆ¶**ï¼šç¡®ä¿æ•°æ®çš„å‡†ç¡®æ€§ã€å®Œæ•´æ€§å’Œæ—¶æ•ˆæ€§
- **å­˜å‚¨ç®¡ç†**ï¼šå»ºç«‹é«˜æ•ˆå¯é çš„æ•°æ®å­˜å‚¨ä½“ç³»
- **æ¥å£æœåŠ¡**ï¼šä¸ºä¸Šå±‚åº”ç”¨æä¾›æ ‡å‡†åŒ–æ•°æ®è®¿é—®

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è§„èŒƒ

### åˆ†å±‚è®¾è®¡åŸåˆ™
```
æ•°æ®æºé€‚é…å±‚ â†’ æ•°æ®å¤„ç†å±‚ â†’ è´¨é‡æ§åˆ¶å±‚ â†’ å­˜å‚¨ç®¡ç†å±‚
     â†“              â†“              â†“              â†“
  APIå®¢æˆ·ç«¯      æ•°æ®æ¸…æ´—å™¨      è´¨é‡æ£€æŸ¥å™¨      æ•°æ®åº“å­˜å‚¨
```

### æ¨¡å—èŒè´£åˆ’åˆ†
- **æ•°æ®æºç®¡ç†å±‚**ï¼šç»Ÿä¸€ç®¡ç†å„ç§æ•°æ®æºçš„æ¥å…¥å’Œé…ç½®
- **é‡‡é›†è°ƒåº¦å±‚**ï¼šæ§åˆ¶æ•°æ®é‡‡é›†çš„æ—¶åºå’Œé¢‘ç‡
- **å¤„ç†å¼•æ“å±‚**ï¼šæ‰§è¡Œæ•°æ®æ¸…æ´—ã€è½¬æ¢å’ŒéªŒè¯
- **è´¨é‡ç›‘æ§å±‚**ï¼šå®æ—¶ç›‘æ§æ•°æ®è´¨é‡å’Œç³»ç»Ÿå¥åº·åº¦

## ğŸ“ æ¨¡å—ç»“æ„è§„èŒƒ

```
data-collector/
â”œâ”€â”€ README.md                 # æœ¬æ–‡ä»¶ - ç³»ç»Ÿæ¶æ„è¯´æ˜
â”œâ”€â”€ data-sources/            # æ•°æ®æºç®¡ç†æ¨¡å—
â”‚   â”œâ”€â”€ source_configs.py    # æ•°æ®æºé…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ api_clients/         # APIå®¢æˆ·ç«¯å®ç°
â”‚   â”‚   â”œâ”€â”€ fred_client.py   # FREDæ•°æ®å®¢æˆ·ç«¯
â”‚   â”‚   â”œâ”€â”€ yahoo_client.py  # Yahoo Financeå®¢æˆ·ç«¯
â”‚   â”‚   â””â”€â”€ sec_client.py    # SEC EDGARå®¢æˆ·ç«¯
â”‚   â””â”€â”€ scrapers/            # ç½‘é¡µæŠ“å–å™¨
â”‚       â”œâ”€â”€ html_parser.py   # HTMLè§£æå™¨
â”‚       â””â”€â”€ data_extractor.py # æ•°æ®æå–å™¨
â”œâ”€â”€ processors/              # æ•°æ®å¤„ç†å™¨æ¨¡å—
â”‚   â”œâ”€â”€ cleaner.py           # æ•°æ®æ¸…æ´—å¼•æ“
â”‚   â”œâ”€â”€ transformer.py       # æ ¼å¼è½¬æ¢å™¨
â”‚   â”œâ”€â”€ validator.py         # æ•°æ®éªŒè¯å™¨
â”‚   â””â”€â”€ enricher.py          # æ•°æ®å¢å¼ºå™¨
â”œâ”€â”€ storage/                 # æ•°æ®å­˜å‚¨æ¨¡å—
â”‚   â”œâ”€â”€ database.py          # æ•°æ®åº“æ“ä½œæ¥å£
â”‚   â”œâ”€â”€ cache.py             # ç¼“å­˜ç®¡ç†å™¨
â”‚   â””â”€â”€ archiver.py          # å†å²æ•°æ®å½’æ¡£
â”œâ”€â”€ quality-control/         # è´¨é‡æ§åˆ¶ç³»ç»Ÿ
â”‚   â”œâ”€â”€ checker.py           # è´¨é‡æ£€æŸ¥å™¨
â”‚   â”œâ”€â”€ monitor.py           # å®æ—¶ç›‘æ§å™¨
â”‚   â””â”€â”€ reporter.py          # è´¨é‡æŠ¥å‘Šç”Ÿæˆå™¨
â””â”€â”€ scheduler/               # ä»»åŠ¡è°ƒåº¦æ¨¡å—
    â”œâ”€â”€ task_manager.py      # ä»»åŠ¡ç®¡ç†å™¨
    â”œâ”€â”€ cron_scheduler.py    # å®šæ—¶è°ƒåº¦å™¨
    â””â”€â”€ priority_queue.py    # ä¼˜å…ˆçº§é˜Ÿåˆ—
```

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½è§„èŒƒ

### 1. å¤šæºæ•°æ®é‡‡é›†ç³»ç»Ÿ
**æ”¯æŒçš„æ•°æ®æºç±»å‹**ï¼š
- å®˜æ–¹ç»Ÿè®¡æ•°æ®ï¼ˆFREDã€World Bankã€å„å›½å¤®è¡Œï¼‰
- é‡‘èå¸‚åœºæ•°æ®ï¼ˆYahoo Financeã€Alpha Vantageï¼‰
- ä¸Šå¸‚å…¬å¸æ•°æ®ï¼ˆSEC EDGARã€å…¬å¸è´¢æŠ¥ï¼‰
- å®è§‚ç»æµæŒ‡æ ‡ï¼ˆPMIã€å°±ä¸šæ•°æ®ã€é€šèƒ€æ•°æ®ï¼‰
- å¦ç±»æ•°æ®ï¼ˆæ–°é—»æƒ…æ„Ÿã€ç¤¾äº¤åª’ä½“æŒ‡æ ‡ï¼‰

**é‡‡é›†ç­–ç•¥è§„èŒƒ**ï¼š
```python
class DataSourceManager:
    """æ•°æ®æºç®¡ç†å™¨ - ç»Ÿä¸€ç®¡ç†å„ç±»æ•°æ®æºçš„æ¥å…¥å’Œé…ç½®"""
    
    def __init__(self):
        self.sources = {}  # æ•°æ®æºæ³¨å†Œè¡¨
        self.rate_limits = {}  # è®¿é—®é¢‘ç‡é™åˆ¶
        self.credentials = {}  # è®¤è¯ä¿¡æ¯ç®¡ç†
        self.health_status = {}  # å¥åº·çŠ¶æ€ç›‘æ§
    
    def register_source(self, source_config):
        """æ³¨å†Œæ•°æ®æº"""
        # éªŒè¯é…ç½®å®Œæ•´æ€§
        # åˆå§‹åŒ–APIå®¢æˆ·ç«¯
        # è®¾ç½®è®¿é—®é¢‘ç‡é™åˆ¶
        # æ³¨å†Œå¥åº·æ£€æŸ¥å›è°ƒ
        pass
    
    def fetch_data(self, source_name, parameters):
        """è·å–æ•°æ®"""
        # æ£€æŸ¥è®¿é—®é¢‘ç‡é™åˆ¶
        # æ‰§è¡ŒAPIè°ƒç”¨
        # å¤„ç†å“åº”æ•°æ®
        # è®°å½•è®¿é—®æ—¥å¿—
        pass
    
    def health_check(self, source_name):
        """å¥åº·çŠ¶æ€æ£€æŸ¥"""
        # æ£€æŸ¥APIå¯ç”¨æ€§
        # éªŒè¯å“åº”æ—¶é—´
        # ç›‘æ§é”™è¯¯ç‡
        # æ›´æ–°å¥åº·çŠ¶æ€
        pass
```

### 2. æ•°æ®å¤„ç†æµæ°´çº¿
**å¤„ç†æ­¥éª¤è§„èŒƒ**ï¼š
1. **æ•°æ®è·å–** - ä»æºè·å–åŸå§‹æ•°æ®
2. **æ ¼å¼æ ‡å‡†åŒ–** - ç»Ÿä¸€æ•°æ®æ ¼å¼å’Œç¼–ç 
3. **å¼‚å¸¸å€¼æ£€æµ‹** - è¯†åˆ«å’Œæ ‡è®°å¼‚å¸¸æ•°æ®
4. **ç¼ºå¤±å€¼å¤„ç†** - åˆç†å¡«è¡¥æˆ–æ ‡è®°ç¼ºå¤±æ•°æ®
5. **è´¨é‡è¯„åˆ†** - è¯„ä¼°æ•°æ®è´¨é‡ç­‰çº§

**å¤„ç†å®ç°ç¤ºä¾‹**ï¼š
```python
# processors/cleaner.py
class DataCleaner:
    """æ•°æ®æ¸…æ´—å™¨ - æ‰§è¡Œä¸“ä¸šçš„æ•°æ®æ¸…ç†æ“ä½œ"""
    
    def __init__(self):
        self.cleaning_rules = self._load_cleaning_rules()
        self.validation_rules = self._load_validation_rules()
    
    def clean_market_data(self, raw_data):
        """æ¸…æ´—å¸‚åœºæ•°æ®"""
        # æ•°æ®ç±»å‹éªŒè¯
        cleaned_data = self._validate_data_types(raw_data)
        
        # é‡å¤è®°å½•å¤„ç†
        cleaned_data = self._remove_duplicates(cleaned_data)
        
        # å¼‚å¸¸å€¼æ£€æµ‹å’Œå¤„ç†
        cleaned_data = self._detect_and_handle_outliers(cleaned_data)
        
        # ç¼ºå¤±å€¼å¤„ç†
        cleaned_data = self._handle_missing_values(cleaned_data)
        
        # æ•°æ®èŒƒå›´éªŒè¯
        cleaned_data = self._validate_data_ranges(cleaned_data)
        
        return cleaned_data
    
    def _detect_outliers(self, data_series, method='iqr'):
        """å¼‚å¸¸å€¼æ£€æµ‹"""
        if method == 'iqr':
            Q1 = data_series.quantile(0.25)
            Q3 = data_series.quantile(0.75)
            IQR = Q3 - Q1
            lower_bound = Q1 - 1.5 * IQR
            upper_bound = Q3 + 1.5 * IQR
            outliers = (data_series < lower_bound) | (data_series > upper_bound)
        elif method == 'zscore':
            z_scores = np.abs(stats.zscore(data_series))
            outliers = z_scores > 3
        return outliers
```

### 3. è´¨é‡æ§åˆ¶ç³»ç»Ÿ
**è´¨é‡è¯„ä¼°ç»´åº¦**ï¼š
- **å®Œæ•´æ€§**ï¼šæ•°æ®æ˜¯å¦å®Œæ•´æ— ç¼ºå¤±ï¼ˆæƒé‡25%ï¼‰
- **å‡†ç¡®æ€§**ï¼šæ•°æ®å€¼æ˜¯å¦åˆç†å‡†ç¡®ï¼ˆæƒé‡30%ï¼‰
- **æ—¶æ•ˆæ€§**ï¼šæ•°æ®æ˜¯å¦åŠæ—¶æ›´æ–°ï¼ˆæƒé‡20%ï¼‰
- **ä¸€è‡´æ€§**ï¼šä¸åŒæ¥æºæ•°æ®æ˜¯å¦ä¸€è‡´ï¼ˆæƒé‡15%ï¼‰
- **å¯é æ€§**ï¼šæ•°æ®æºæ˜¯å¦å¯ä¿¡ï¼ˆæƒé‡10%ï¼‰

**è´¨é‡ç›‘æ§å®ç°**ï¼š
```python
# quality-control/checker.py
class QualityChecker:
    """è´¨é‡æ£€æŸ¥å™¨ - æ‰§è¡Œå…¨é¢çš„æ•°æ®è´¨é‡è¯„ä¼°"""
    
    def __init__(self):
        self.quality_weights = {
            'completeness': 0.25,
            'accuracy': 0.30,
            'timeliness': 0.20,
            'consistency': 0.15,
            'reliability': 0.10
        }
        self.thresholds = {
            'minimum_score': 0.80,
            'critical_error_threshold': 0.50
        }
    
    def assess_data_quality(self, data, source_info):
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        quality_scores = {}
        
        # å®Œæ•´æ€§æ£€æŸ¥
        quality_scores['completeness'] = self._check_completeness(data)
        
        # å‡†ç¡®æ€§éªŒè¯
        quality_scores['accuracy'] = self._check_accuracy(data, source_info)
        
        # æ—¶æ•ˆæ€§è¯„ä¼°
        quality_scores['timeliness'] = self._check_timeliness(data)
        
        # ä¸€è‡´æ€§æ£€æŸ¥
        quality_scores['consistency'] = self._check_consistency(data)
        
        # å¯é æ€§è¯„åˆ†
        quality_scores['reliability'] = self._assess_reliability(source_info)
        
        # è®¡ç®—ç»¼åˆè´¨é‡åˆ†æ•°
        overall_score = self._calculate_weighted_score(quality_scores)
        
        return {
            'scores': quality_scores,
            'overall_score': overall_score,
            'issues': self._identify_quality_issues(quality_scores),
            'recommendations': self._generate_improvement_suggestions(quality_scores)
        }
    
    def _check_completeness(self, data):
        """æ£€æŸ¥æ•°æ®å®Œæ•´æ€§"""
        total_records = len(data)
        complete_records = data.dropna().shape[0]
        completeness_ratio = complete_records / total_records
        return completeness_ratio
```

### 4. å­˜å‚¨ç®¡ç†ç­–ç•¥
**å­˜å‚¨åˆ†å±‚è§„èŒƒ**ï¼š
- **çƒ­æ•°æ®**ï¼šæœ€è¿‘1å¹´çš„é«˜é¢‘è®¿é—®æ•°æ®
- **æ¸©æ•°æ®**ï¼š1-5å¹´çš„ä¸­é¢‘è®¿é—®æ•°æ®
- **å†·æ•°æ®**ï¼š5å¹´ä»¥ä¸Šçš„ä½é¢‘è®¿é—®æ•°æ®

**æ•°æ®åº“è®¾è®¡**ï¼š
```sql
-- æ ¸å¿ƒæ•°æ®è¡¨ç»“æ„
CREATE TABLE market_data (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    symbol TEXT NOT NULL,
    date DATE NOT NULL,
    open_price REAL,
    high_price REAL,
    low_price REAL,
    close_price REAL NOT NULL,
    volume INTEGER,
    adjusted_close REAL,
    dividend REAL DEFAULT 0,
    split_coefficient REAL DEFAULT 1,
    source TEXT NOT NULL,
    quality_score REAL DEFAULT 1.0,
    fetched_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    processed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    UNIQUE(symbol, date, source)
);

-- å…ƒæ•°æ®è¡¨
CREATE TABLE data_source_metadata (
    source_name TEXT PRIMARY KEY,
    source_type TEXT NOT NULL,
    base_url TEXT,
    api_endpoint TEXT,
    last_accessed TIMESTAMP,
    success_rate REAL DEFAULT 1.0,
    average_response_time REAL,
    reliability_score REAL DEFAULT 1.0,
    supported_indicators TEXT,
    rate_limit INTEGER,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- è´¨é‡ç›‘æ§è¡¨
CREATE TABLE data_quality_log (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    data_table TEXT NOT NULL,
    check_date DATE NOT NULL,
    completeness_score REAL,
    accuracy_score REAL,
    timeliness_score REAL,
    consistency_score REAL,
    overall_score REAL,
    issues_found TEXT,
    checked_by TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

## ğŸ“Š APIæ¥å£è§„èŒƒ

### å†…éƒ¨APIè®¾è®¡
```python
class DataCollectorAPI:
    """æ•°æ®æ”¶é›†å™¨APIæ¥å£ - æä¾›æ ‡å‡†åŒ–çš„æ•°æ®è®¿é—®æœåŠ¡"""
    
    def get_latest_data(self, symbol, data_type="market"):
        """è·å–æœ€æ–°æ•°æ®"""
        # å‚æ•°éªŒè¯
        # æ•°æ®æŸ¥è¯¢
        # è´¨é‡æ£€æŸ¥
        # è¿”å›æ ‡å‡†åŒ–æ ¼å¼
        pass
    
    def get_historical_data(self, symbol, start_date, end_date):
        """è·å–å†å²æ•°æ®"""
        # æ—¥æœŸèŒƒå›´éªŒè¯
        # æ‰¹é‡æ•°æ®æŸ¥è¯¢
        # æ•°æ®æ’åºå’Œæ ¼å¼åŒ–
        # åˆ†é¡µè¿”å›æ”¯æŒ
        pass
    
    def get_data_quality_report(self, symbol=None, date_range=None):
        """è·å–æ•°æ®è´¨é‡æŠ¥å‘Š"""
        # è´¨é‡æŒ‡æ ‡æŸ¥è¯¢
        # ç»Ÿè®¡åˆ†æè®¡ç®—
        # æŠ¥å‘Šæ ¼å¼åŒ–
        # å¯è§†åŒ–æ•°æ®å‡†å¤‡
        pass
    
    def force_refresh_source(self, source_name):
        """å¼ºåˆ¶åˆ·æ–°æ•°æ®æº"""
        # æƒé™éªŒè¯
        # ç«‹å³æ‰§è¡Œé‡‡é›†
        # çŠ¶æ€æ›´æ–°
        # ç»“æœåé¦ˆ
        pass
```

### å¤–éƒ¨æ¥å£è§„èŒƒï¼ˆæœªæ¥æ‰©å±•ï¼‰
```python
# RESTful APIè®¾è®¡ç¤ºä¾‹
@app.route('/api/v1/data/<symbol>', methods=['GET'])
def get_symbol_data(symbol):
    """è·å–æŒ‡å®šæ ‡çš„çš„æ•°æ®"""
    # è®¤è¯å’Œæˆæƒæ£€æŸ¥
    # å‚æ•°è§£æå’ŒéªŒè¯
    # æ•°æ®æŸ¥è¯¢å’Œå¤„ç†
    # JSONæ ¼å¼å“åº”
    pass

@app.route('/api/v1/quality/metrics', methods=['GET'])
def get_quality_metrics():
    """è·å–æ•°æ®è´¨é‡æŒ‡æ ‡"""
    # èšåˆè´¨é‡ç»Ÿè®¡æ•°æ®
    # è®¡ç®—å„é¡¹æŒ‡æ ‡
    # è¿”å›æ ‡å‡†åŒ–è´¨é‡æŠ¥å‘Š
    pass
```

## ğŸ”§ é…ç½®ç®¡ç†è§„èŒƒ

### æ•°æ®æºé…ç½®æ–‡ä»¶
```yaml
# config/data_sources.yaml
sources:
  fred:
    name: "Federal Reserve Economic Data"
    type: "official"
    base_url: "https://api.stlouisfed.org/fred"
    api_key: "${FRED_API_KEY}"
    rate_limit: 120  # æ¯åˆ†é’Ÿè¯·æ±‚æ•°
    reliability: 0.99
    supported_series: 
      - "GDP"
      - "UNRATE"
      - "CPIAUCSL"
      - "FEDFUNDS"
  
  yahoo_finance:
    name: "Yahoo Finance API"
    type: "financial"
    base_url: "https://query1.finance.yahoo.com"
    rate_limit: 2000
    reliability: 0.95
    supported_symbols:
      - "^GSPC"  # S&P 500
      - "AAPL"
      - "GOOGL"
      - "MSFT"
  
  sec_edgar:
    name: "SEC EDGAR Database"
    type: "regulatory"
    base_url: "https://data.sec.gov"
    rate_limit: 10
    reliability: 0.98
    supported_forms:
      - "10-K"
      - "10-Q"
      - "13F-HR"

collection_schedule:
  real_time: ["market_data"]  # å®æ—¶æ›´æ–°
  daily: ["economic_indicators", "fundamental_data"]  # æ¯æ—¥æ›´æ–°
  weekly: ["company_filings", "alternative_data"]  # æ¯å‘¨æ›´æ–°
  monthly: ["macro_reports", "industry_analysis"]  # æ¯æœˆæ›´æ–°
```

### å¤„ç†è§„åˆ™é…ç½®
```python
# config/processing_rules.py
PROCESSING_RULES = {
    'market_data': {
        'required_fields': ['symbol', 'date', 'close_price'],
        'validation_rules': {
            'price_range': (0, 1000000),  # ä»·æ ¼èŒƒå›´éªŒè¯
            'volume_range': (0, 10000000000),  # æˆäº¤é‡èŒƒå›´
            'date_format': '%Y-%m-%d'  # æ—¥æœŸæ ¼å¼
        },
        'cleaning_rules': {
            'handle_duplicates': 'keep_latest',  # é‡å¤æ•°æ®å¤„ç†ç­–ç•¥
            'missing_price_strategy': 'forward_fill',  # ç¼ºå¤±ä»·æ ¼å¡«è¡¥
            'outlier_detection': 'modified_zscore',  # å¼‚å¸¸å€¼æ£€æµ‹æ–¹æ³•
            'outlier_threshold': 3.5  # å¼‚å¸¸å€¼é˜ˆå€¼
        }
    },
    'economic_indicators': {
        'required_fields': ['indicator_name', 'date', 'value'],
        'validation_rules': {
            'value_range': (-1000000, 1000000),  # æŒ‡æ ‡å€¼èŒƒå›´
            'frequency_options': ['daily', 'weekly', 'monthly', 'quarterly', 'yearly']
        }
    }
}
```

## ğŸš€ éƒ¨ç½²å’Œè¿è¡Œè§„èŒƒ

### è¿è¡Œç¯å¢ƒè¦æ±‚
```bash
# ç³»ç»Ÿä¾èµ–æ£€æŸ¥
python --version  # Python 3.14+
pip list | grep -E "(requests|pandas|numpy|sqlite3)"  # æ ¸å¿ƒä¾èµ–

# ç¯å¢ƒå˜é‡è®¾ç½®
export FRED_API_KEY="your_api_key_here"
export DATA_COLLECTOR_CONFIG="config/data_sources.yaml"

# ç³»ç»Ÿå¯åŠ¨
cd software-modules/data-collector
python collector_main.py --config config/data_sources.yaml

# è°ƒåº¦æœåŠ¡å¯åŠ¨
python scheduler_service.py --daemon
```

### ç³»ç»Ÿç›‘æ§è§„èŒƒ
```python
class SystemMonitor:
    """ç³»ç»Ÿç›‘æ§å™¨ - å®æ—¶ç›‘æ§æ•°æ®æ”¶é›†å™¨è¿è¡ŒçŠ¶æ€"""
    
    def __init__(self):
        self.metrics = {
            'collection_success_rate': 0.0,
            'average_processing_time': 0.0,
            'data_quality_score': 0.0,
            'storage_utilization': 0.0,
            'active_connections': 0
        }
        self.alert_thresholds = {
            'success_rate': 0.95,
            'processing_time': 30.0,  # ç§’
            'quality_score': 0.80,
            'storage_usage': 0.85
        }
    
    def collect_system_metrics(self):
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        # CPUå’Œå†…å­˜ä½¿ç”¨ç‡
        # ç£ç›˜ç©ºé—´ä½¿ç”¨æƒ…å†µ
        # ç½‘ç»œè¿æ¥çŠ¶æ€
        # æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡
        pass
    
    def generate_health_report(self):
        """ç”Ÿæˆå¥åº·æŠ¥å‘Š"""
        # ç³»ç»ŸçŠ¶æ€è¯„ä¼°
        # æ€§èƒ½ç“¶é¢ˆè¯†åˆ«
        # æ”¹è¿›å»ºè®®ç”Ÿæˆ
        # å‘Šè­¦ä¿¡æ¯æ±‡æ€»
        pass
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–è§„èŒƒ

### å¹¶å‘å¤„ç†æœºåˆ¶
```python
class ConcurrentCollector:
    """å¹¶å‘æ”¶é›†å™¨ - æ”¯æŒå¤šæ•°æ®æºå¹¶è¡Œé‡‡é›†"""
    
    def __init__(self, max_workers=10):
        self.executor = ThreadPoolExecutor(max_workers=max_workers)
        self.semaphores = {}  # ç”¨äºæ§åˆ¶è®¿é—®é¢‘ç‡
        self.timeout_settings = {}  # è¶…æ—¶é…ç½®
    
    def collect_multiple_sources(self, source_configs):
        """å¹¶å‘æ”¶é›†å¤šä¸ªæ•°æ®æº"""
        futures = []
        for config in source_configs:
            # åº”ç”¨è®¿é—®é¢‘ç‡æ§åˆ¶
            semaphore = self._get_semaphore(config['source_name'])
            future = self.executor.submit(
                self._collect_with_semaphore, 
                config, 
                semaphore
            )
            futures.append(future)
        
        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        results = []
        for future in futures:
            try:
                result = future.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶
                results.append(result)
            except Exception as e:
                logger.error(f"æ•°æ®é‡‡é›†å¤±è´¥: {e}")
                results.append(None)
        
        return results
```

### ç¼“å­˜ä¼˜åŒ–ç­–ç•¥
```python
class SmartCache:
    """æ™ºèƒ½ç¼“å­˜ç®¡ç†å™¨ - ä¼˜åŒ–æ•°æ®è®¿é—®æ€§èƒ½"""
    
    def __init__(self):
        self.cache = {}  # å†…å­˜ç¼“å­˜
        self.redis_client = None  # Rediså®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
        self.access_patterns = {}  # è®¿é—®æ¨¡å¼ç»Ÿè®¡
        self.expiration_policies = {}  # è¿‡æœŸç­–ç•¥
    
    def get_with_ttl(self, key, ttl=3600):
        """å¸¦TTLçš„ç¼“å­˜è·å–"""
        # æ£€æŸ¥å†…å­˜ç¼“å­˜
        if key in self.cache:
            data, expiry_time = self.cache[key]
            if time.time() < expiry_time:
                self._update_access_pattern(key)
                return data
            else:
                del self.cache[key]
        
        # æ£€æŸ¥æŒä¹…åŒ–ç¼“å­˜
        if self.redis_client:
            cached_data = self.redis_client.get(key)
            if cached_data:
                self.cache[key] = (cached_data, time.time() + ttl)
                return cached_data
        
        return None
    
    def set_with_ttl(self, key, data, ttl=3600):
        """å¸¦TTLçš„ç¼“å­˜è®¾ç½®"""
        expiry_time = time.time() + ttl
        self.cache[key] = (data, expiry_time)
        
        # åŒæ­¥åˆ°æŒä¹…åŒ–å­˜å‚¨
        if self.redis_client:
            self.redis_client.setex(key, ttl, data)
        
        self._update_access_pattern(key)
```

## ğŸ” å®‰å…¨ä¸åˆè§„è§„èŒƒ

### è®¿é—®æ§åˆ¶æœºåˆ¶
```python
class AccessController:
    """è®¿é—®æ§åˆ¶å™¨ - ç®¡ç†æ•°æ®è®¿é—®æƒé™å’Œå®‰å…¨æ§åˆ¶"""
    
    def __init__(self):
        self.api_keys = {}  # APIå¯†é’¥ç®¡ç†
        self.rate_limits = {}  # è®¿é—®é¢‘ç‡é™åˆ¶
        self.blocked_ips = set()  # é»‘åå•IP
        self.access_logs = []  # è®¿é—®æ—¥å¿—
    
    def validate_api_key(self, api_key, required_permissions=None):
        """éªŒè¯APIå¯†é’¥æƒé™"""
        if api_key not in self.api_keys:
            raise AuthenticationError("æ— æ•ˆçš„APIå¯†é’¥")
        
        key_info = self.api_keys[api_key]
        if key_info['status'] != 'active':
            raise AuthorizationError("APIå¯†é’¥å·²è¢«ç¦ç”¨")
        
        if required_permissions:
            user_permissions = set(key_info['permissions'])
            required_set = set(required_permissions)
            if not required_set.issubset(user_permissions):
                raise AuthorizationError("æƒé™ä¸è¶³")
        
        return True
    
    def check_rate_limit(self, client_identifier, endpoint=None):
        """æ£€æŸ¥è®¿é—®é¢‘ç‡é™åˆ¶"""
        current_time = time.time()
        window_start = current_time - 3600  # 1å°æ—¶çª—å£
        
        # æ¸…ç†è¿‡æœŸè®°å½•
        self.access_logs = [
            log for log in self.access_logs 
            if log['timestamp'] > window_start
        ]
        
        # ç»Ÿè®¡å½“å‰è®¿é—®æ¬¡æ•°
        recent_accesses = [
            log for log in self.access_logs 
            if log['client'] == client_identifier
        ]
        
        if len(recent_accesses) >= self.rate_limits.get(endpoint, 1000):
            raise RateLimitError("è®¿é—®é¢‘ç‡è¶…å‡ºé™åˆ¶")
        
        # è®°å½•æœ¬æ¬¡è®¿é—®
        self.access_logs.append({
            'client': client_identifier,
            'endpoint': endpoint,
            'timestamp': current_time
        })
```

### æ•°æ®åˆè§„è¦æ±‚
- ä¸¥æ ¼éµå®ˆå„æ•°æ®æºçš„ä½¿ç”¨æ¡æ¬¾å’Œè®¸å¯åè®®
- å»ºç«‹å®Œæ•´çš„æ•°æ®ä½¿ç”¨æ—¥å¿—å’Œå®¡è®¡è¿½è¸ª
- å®šæœŸå®¡æŸ¥æ•°æ®é‡‡é›†å’Œä½¿ç”¨åˆè§„æ€§
- å®æ–½æ•°æ®æœ€å°åŒ–åŸåˆ™ï¼Œåªé‡‡é›†å¿…è¦æ•°æ®
- å»ºç«‹æ•°æ®åˆ é™¤å’Œæ¸…ç†æœºåˆ¶

## ğŸ› ï¸ ç»´æŠ¤å’Œæ”¯æŒè§„èŒƒ

### æ—¥å¿—ç³»ç»Ÿè§„èŒƒ
```python
import logging
import logging.handlers

class DataCollectorLogger:
    """æ•°æ®æ”¶é›†å™¨æ—¥å¿—ç³»ç»Ÿ - æä¾›å®Œæ•´çš„æ—¥å¿—è®°å½•åŠŸèƒ½"""
    
    def __init__(self, log_level=logging.INFO):
        self.logger = logging.getLogger('data_collector')
        self.logger.setLevel(log_level)
        
        # æ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.handlers.RotatingFileHandler(
            'logs/data_collector.log',
            maxBytes=50*1024*1024,  # 50MB
            backupCount=5
        )
        file_handler.setFormatter(
            logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
        )
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(
            logging.Formatter(
                '%(levelname)s - %(message)s'
            )
        )
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
    
    def log_collection_attempt(self, source, status, details=None):
        """è®°å½•æ•°æ®é‡‡é›†å°è¯•"""
        message = f"æ•°æ®é‡‡é›† [{source}] - çŠ¶æ€: {status}"
        if details:
            message += f" - è¯¦æƒ…: {details}"
        
        if status == 'SUCCESS':
            self.logger.info(message)
        elif status == 'FAILED':
            self.logger.error(message)
        else:
            self.logger.warning(message)
    
    def log_data_quality_issue(self, issue_type, severity, details):
        """è®°å½•æ•°æ®è´¨é‡é—®é¢˜"""
        message = f"æ•°æ®è´¨é‡é—®é¢˜ [{issue_type}] - ä¸¥é‡æ€§: {severity} - {details}"
        if severity == 'HIGH':
            self.logger.error(message)
        elif severity == 'MEDIUM':
            self.logger.warning(message)
        else:
            self.logger.info(message)
```

### æ•…éšœæ¢å¤æœºåˆ¶
```python
class RecoveryManager:
    """æ•…éšœæ¢å¤ç®¡ç†å™¨ - å¤„ç†ç³»ç»Ÿæ•…éšœå’Œå¼‚å¸¸æƒ…å†µ"""
    
    def __init__(self):
        self.retry_policies = {
            'network_errors': {'max_attempts': 3, 'delay': 5},
            'api_errors': {'max_attempts': 2, 'delay': 10},
            'database_errors': {'max_attempts': 1, 'delay': 0}
        }
        self.backup_sources = {}  # å¤‡ç”¨æ•°æ®æºé…ç½®
        self.failure_history = []  # æ•…éšœå†å²è®°å½•
    
    def handle_source_failure(self, source_name, error):
        """å¤„ç†æ•°æ®æºæ•…éšœ"""
        # è®°å½•æ•…éšœä¿¡æ¯
        failure_record = {
            'source': source_name,
            'error': str(error),
            'timestamp': datetime.now(),
            'attempt_count': 1
        }
        self.failure_history.append(failure_record)
        
        # å°è¯•å¤‡ç”¨æ–¹æ¡ˆ
        if source_name in self.backup_sources:
            return self._switch_to_backup_source(source_name)
        
        # å®æ–½é‡è¯•ç­–ç•¥
        retry_policy = self._get_retry_policy(error)
        return self._execute_retry_strategy(source_name, error, retry_policy)
    
    def _switch_to_backup_source(self, primary_source):
        """åˆ‡æ¢åˆ°å¤‡ç”¨æ•°æ®æº"""
        backup_config = self.backup_sources[primary_source]
        # åˆå§‹åŒ–å¤‡ç”¨æºè¿æ¥
        # éªŒè¯å¤‡ç”¨æºå¯ç”¨æ€§
        # æ›´æ–°æ•°æ®æºé…ç½®
        pass
```

## ğŸ”„ æ›´æ–°åŸåˆ™

### æ–‡æ¡£ç»´æŠ¤è¦æ±‚
- æ¯æ¬¡åŠŸèƒ½æ›´æ–°å¿…é¡»åŒæ­¥æ›´æ–°ç›¸å…³æ–‡æ¡£
- ä¿æŒä¸ä¸»çŸ¥è¯†ä½“ç³»æ–‡æ¡£çš„ä¸€è‡´æ€§
- ç»´æŠ¤å®Œæ•´çš„ç‰ˆæœ¬å˜æ›´è®°å½•
- å®šæœŸè¿›è¡Œæ–‡æ¡£è´¨é‡å®¡æŸ¥

### è´¨é‡ä¿è¯æªæ–½
- ä»£ç å®¡æŸ¥å’ŒåŒè¡Œè¯„å®¡åˆ¶åº¦
- å•å…ƒæµ‹è¯•å’Œé›†æˆæµ‹è¯•è¦†ç›–â‰¥90%
- æ•°æ®è´¨é‡æŒç»­ç›‘æ§å’ŒæŠ¥å‘Š
- ç”¨æˆ·åé¦ˆæ”¶é›†å’Œå¤„ç†æœºåˆ¶

---
*æœ¬æ–‡æ¡£éµå¾ªé¡¹ç›®æ¶æ„è®¾è®¡è§„èŒƒï¼Œä»»ä½•ä¿®æ”¹éƒ½å¿…é¡»ç»è¿‡ä¸¥æ ¼è¯„å®¡å’Œæµ‹è¯•éªŒè¯*